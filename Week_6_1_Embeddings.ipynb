{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NaomiKemi/InClassAssignments/blob/main/Week_6_1_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_ANG0-y6uD1"
      },
      "outputs": [],
      "source": [
        "#Adapted from the Keras Example https://keras.io/examples/structured_data/collaborative_filtering_movielens/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MgYPh7i6uD6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPbtKkKN6uD6"
      },
      "source": [
        "# Week 6.1- Embeddings for Recommendation\n",
        "\n",
        "Here we'll see how to train our simple **Dot Product** model, along with our **user embeddings** and **item embeddings** using the **Keras** library. As before, we'll be checking out the **MovieLens** dataset\n",
        "\n",
        "## Loading in the Dataset\n",
        "\n",
        "First we load in the small version of the dataset. As this is a **Collaborative Filtering** approach, we are interested in the **ratings.csv**, which has all over ratings made by each user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2-BvgMy6uD9"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"ratings.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28L2AHzF6uD9",
        "outputId": "b8eb1794-ca14-486d-fa44-dd77c28d0aa5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100004"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "eEhV72Qs6uD-",
        "outputId": "de23c522-c9a3-4b3a-e2dd-5bb3f1f73d0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        userId  movieId  rating   timestamp\n",
              "99904      671      590     4.0  1065149296\n",
              "99905      671      608     4.0  1064890575\n",
              "99906      671      745     4.0  1065149085\n",
              "99907      671      919     4.0  1065149458\n",
              "99908      671     1035     5.0  1065149492\n",
              "...        ...      ...     ...         ...\n",
              "99999      671     6268     2.5  1065579370\n",
              "100000     671     6269     4.0  1065149201\n",
              "100001     671     6365     4.0  1070940363\n",
              "100002     671     6385     2.5  1070979663\n",
              "100003     671     6565     3.5  1074784724\n",
              "\n",
              "[100 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5527702d-876e-43ad-8469-863f58784910\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>99904</th>\n",
              "      <td>671</td>\n",
              "      <td>590</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1065149296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99905</th>\n",
              "      <td>671</td>\n",
              "      <td>608</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1064890575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99906</th>\n",
              "      <td>671</td>\n",
              "      <td>745</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1065149085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99907</th>\n",
              "      <td>671</td>\n",
              "      <td>919</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1065149458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99908</th>\n",
              "      <td>671</td>\n",
              "      <td>1035</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1065149492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>671</td>\n",
              "      <td>6268</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1065579370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100000</th>\n",
              "      <td>671</td>\n",
              "      <td>6269</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1065149201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100001</th>\n",
              "      <td>671</td>\n",
              "      <td>6365</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1070940363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100002</th>\n",
              "      <td>671</td>\n",
              "      <td>6385</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1070979663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100003</th>\n",
              "      <td>671</td>\n",
              "      <td>6565</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1074784724</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows Ã— 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5527702d-876e-43ad-8469-863f58784910')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5527702d-876e-43ad-8469-863f58784910 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5527702d-876e-43ad-8469-863f58784910');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.tail(100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8LSXtqH6uD_"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "What we have in the dataset is a list of **userId** and **movieId** pairs loaded into a ``Pandas`` DataFrame.\n",
        "\n",
        "As we said before, you can think of an embedding layer as a **one-hot encoding** layer the size of your **vocabulary**, followed by a **fully connected layer** the size of your embedding.\n",
        "\n",
        "When we make the embedding, we will need a way of mapping back from **indexes** in the **one-hot encoding** back to the ids for the users and movies.\n",
        "\n",
        "### Vocabulary\n",
        "\n",
        "In order to make the vocabulary (all the unique ids), we can use the ``unique()`` function in ``Pandas``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yA_NfifF6uD_"
      },
      "outputs": [],
      "source": [
        "user_ids = df[\"userId\"].unique().tolist()\n",
        "movie_ids = df[\"movieId\"].unique().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brZx_yYY6uD_",
        "outputId": "01e9e12e-dc43-4e49-fe7c-1047db85dacb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9066"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(movie_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOinLCRC6uEA",
        "outputId": "123a3da2-166f-4cfa-c7ad-bed0399d16d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[31, 1029, 1061, 1129, 1172, 1263]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Non-sequential list of ids\n",
        "movie_ids[:6]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FWobKmt6uEA"
      },
      "source": [
        "### Dictionary Comprehensions\n",
        "\n",
        "We've seen ``Dictionaries`` (e.g. when looking at JSON from REST APIs). This is a collection like a ``List``, but instead of using indexes to access data (**values**), we use **keys**.\n",
        "\n",
        "We've also seen ``List Comprehensions``, a short hand way to iterate through an existing collection and make a new ``List``.\n",
        "\n",
        "As we want something where we can use an arbitrary string/number (e.g. a movie or user id) to look up an index, a ``Dictionary`` seems like a good data structure to use. We can declare dictionaries manually (see below), but it would be much quicker and cleaner to use the information we already have to make this.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsPCw0vQ6uEB",
        "outputId": "403438ca-5d16-4c2e-9bc9-87cc2aa4fbad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Manually making the dictionary\n",
        "movie_id_to_index = {\n",
        "    31: 1,\n",
        "    1029: 2,\n",
        "    1061: 3\n",
        "}\n",
        "#Use a movie id to look up an index\n",
        "movie_id_to_index[31]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nxdh2vq6uEB"
      },
      "source": [
        "Like the ``List Comprehension``, the ``Dictionary Comprehension`` iterates through a given collection, does some calculation and stores new values in a new collection.\n",
        "\n",
        "In this case, we need to return both a ``Key`` and a ``Value`` for each item.\n",
        "\n",
        "```\n",
        "a = [1,2,3]\n",
        "b = {i:i+1 for i in a}\n",
        "```\n",
        "\n",
        "is the same as\n",
        "\n",
        "```\n",
        "a = [1,2,3]\n",
        "b = {}\n",
        "for i in a:\n",
        "    b[i] = i+1\n",
        "```\n",
        "\n",
        "where we end up with the ``Dictionary``\n",
        "\n",
        "```\n",
        "{\n",
        "    1: 2,\n",
        "    2: 3,\n",
        "    3: 4\n",
        "}\n",
        "```\n",
        "\n",
        "Below, we combine the dictionary comprehension with the ``enumerate()`` function to return the id (x) and the index (i) and store them in a new dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZxjpJA46uEC"
      },
      "outputs": [],
      "source": [
        "#Make a dictionary mapping ids (keys) to indexes (values)\n",
        "user_id_to_index = {x: i for i, x in enumerate(user_ids)}\n",
        "movie_id_to_index = {x: i for i, x in enumerate(movie_ids)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIW_UXgJ6uEC"
      },
      "outputs": [],
      "source": [
        "#Make a new column in the dataframe which contains the appropriate index for each user and movie\n",
        "df[\"user_index\"] = [user_id_to_index[i] for i in df[\"userId\"]]\n",
        "df[\"movie_index\"] = [movie_id_to_index[i] for i in df[\"movieId\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDajSvOH6uED",
        "outputId": "57d5e402-df7a-43e0-fa71-bf196c839f3f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>user_index</th>\n",
              "      <th>movie_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1260759144</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1029</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1260759179</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1061</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1260759182</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1129</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1260759185</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1172</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1260759205</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating   timestamp  user_index  movie_index\n",
              "0       1       31     2.5  1260759144           0            0\n",
              "1       1     1029     3.0  1260759179           0            1\n",
              "2       1     1061     3.0  1260759182           0            2\n",
              "3       1     1129     2.0  1260759185           0            3\n",
              "4       1     1172     4.0  1260759205           0            4"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFn6zYIZ6uED"
      },
      "source": [
        "###Â Scaling the ratings\n",
        "\n",
        "As is good when working with ``gradient descent``, it helps to have our values on a similar range, and for that to be between 0 and 1. We can use the ``MinMaxScaler`` from ``Scikit-Learn`` to scale our ratings to between 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkR36EDQ6uEE",
        "outputId": "d82eb2d3-96eb-40f0-d2cf-a2095b653554"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    100004.000000\n",
              "mean          3.543608\n",
              "std           1.058064\n",
              "min           0.500000\n",
              "25%           3.000000\n",
              "50%           4.000000\n",
              "75%           4.000000\n",
              "max           5.000000\n",
              "Name: rating, dtype: float64"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"rating\"].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agrJh4MX6uEE"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "##Pick the range\\\n",
        "df[\"rating\"] = MinMaxScaler().fit_transform(df[\"rating\"].values.reshape(-1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwL3zjTG6uEE",
        "outputId": "211b6c28-81d1-427c-9905-99e7a354b30d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    100004.000000\n",
              "mean          0.676357\n",
              "std           0.235125\n",
              "min           0.000000\n",
              "25%           0.555556\n",
              "50%           0.777778\n",
              "75%           0.777778\n",
              "max           1.000000\n",
              "Name: rating, dtype: float64"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"rating\"].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhhrmC686uEF"
      },
      "source": [
        "## Training Set\n",
        "\n",
        "We are making a **predictive model** that will take a **user** and **movie** and return a **rating**.\n",
        "\n",
        "For our training, we will make a dataset using the information we already know. In this context, our input feautres (``x``) are the movie and user indexes, and the our output (``y``) is the rating.\n",
        "\n",
        "We make a train - test split of ``10%`` to validate our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cEzYstl6uEF"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#Inputs\n",
        "x = df[[\"user_index\", \"movie_index\"]]\n",
        "#Outputs\n",
        "y = df[\"rating\"]\n",
        "#Get train-test split\n",
        "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtXOwXK06uEF"
      },
      "source": [
        "## Making a Custom Model\n",
        "\n",
        "Previously in ``Keras`` we have used to pre-existing layers, connecting them all together in using the [Sequential](https://keras.io/guides/sequential_model/) object. This allows us to fit together layers that pass information forwards in a structure that works for most **Neural Networks**.\n",
        "\n",
        "Partly for reasons of broadening our horizons, and partly due to many Tensorflow based issues, we are going to introduce you to what is fastly becoming the most popular machine learning library, ``PyTorch``.\n",
        "\n",
        "Luckily for us, the API (the functions, the structure of models etc..) are very similar across a lot of the leading libraries.\n",
        "\n",
        "``PyTorch`` has a [Module]() object which we can **subclass**. Without getting too bogged down in the details of **Object Oriented Programming**, essentially what this means is we can take the **existing functionality** from this object and **override** certain functions to add in custom behaviour.\n",
        "\n",
        "Using the ``Module`` structure, we have something that can take advantage of a lot the things that are built into the ``PyTorch`` library. It can be trained, can have layers, can have parameters that can be optimised.\n",
        "\n",
        "**But**, we can also add in our own functionality.\n",
        "\n",
        "The two main functions we want to override and these are\n",
        "\n",
        "1. ``def __init__()``\n",
        "\n",
        "    * This is called **once** when the object is first made. We can use this to define our layers\n",
        "\n",
        "\n",
        "2. ``def forward()``\n",
        "\n",
        "    * This is called everytime we want to make a forwards pass. This means it takes some **inputs** and returns some **outputs**. This is called during training, or for inference on a trained model.\n",
        "\n",
        "### LouisNet\n",
        "\n",
        "Below, we show an **incredibly simple model**, but it should help you get an intuition for what function is called at when in the training process\n",
        "\n",
        "We can see the ``__init__()`` is called once, and then the ``call()`` is called **once per batch**, where we get the inputs for this batch and return some outputs\n",
        "\n",
        "This model doesnt actually have any parameters to train, its more to demonstrate the subclassing principle in the simplest terms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpxkQ6BP6uEF",
        "outputId": "8938babb-33b3-4304-9829-8aaf6d368b55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.0.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "#Install libraries (only do this once!)\n",
        "!pip install torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izK3snPq6uEG"
      },
      "outputs": [],
      "source": [
        "#import library\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErXCFXiy6uEG",
        "outputId": "cffee2db-7654-420e-d42c-9e70c6237fe8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "__init__ called\n",
            "\n",
            "forwards pass (new batch)\n",
            "tensor([[1.],\n",
            "        [2.],\n",
            "        [3.],\n",
            "        [4.]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Define class and subclass torch.nn.Module\n",
        "class LouisNet(torch.nn.Module):\n",
        "\n",
        "    #Override __init__()\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        print(\"__init__ called\")\n",
        "\n",
        "    #Override forward()\n",
        "    def forward(self, inputs):\n",
        "        print(\"\\nforwards pass (new batch)\")\n",
        "        print(inputs,\"\\n\")\n",
        "        #return the output (its just the input, unchanged)\n",
        "        return inputs\n",
        "\n",
        "#Make a new instance of LouisNet\n",
        "louisNet = LouisNet()\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "#Fake dataset\n",
        "x = torch.FloatTensor([[1],[2],[3],[4]])\n",
        "y = torch.FloatTensor([[2],[3],[4],[5]])\n",
        "\n",
        "#Do a forwards pass\n",
        "prediction = louisNet(x)\n",
        "loss = loss_fn(prediction, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX-Hwy3l6uEG"
      },
      "source": [
        "## The Dot Product Recommender Model\n",
        "\n",
        "Lets remember the model we're trying to make.\n",
        "\n",
        "\n",
        "```\n",
        "Predicted Rating = Dot Product(user_vector, item_vector) + user_bias + item_bias\n",
        "```\n",
        "\n",
        "\n",
        "Our target is to find a vector for each movie and user so that their dot product (+ their biases) is an accurate prediction for the rating that user would make for that movie.\n",
        "\n",
        "Each of these vectors will be contained in a matrix, that we call an **embedding**\n",
        "\n",
        "\n",
        "### The Embedding Layer\n",
        "\n",
        "Again, you can think of an embedding layer as a **one-hot encoding** layer the size of your **vocabulary**, followed by a **fully connected layer** the size of your embedding.\n",
        "\n",
        "Luckily, ```PyTorch``` has a layer already we can use, all we have to say is\n",
        "\n",
        "1. How many items we have (vocabulary size)\n",
        "\n",
        "2. The size of the embedding\n",
        "\n",
        "You might use something between 10-300, and this is something you will have to tune\n",
        "\n",
        "### New Arguments for ``__init__``\n",
        "\n",
        "Again, we will override the ```__init__()``` function, but this time we will add in some extra arguments. We can use this to pass in\n",
        "\n",
        "1. Number of users\n",
        "\n",
        "2. Number of movies\n",
        "\n",
        "3. Size of Embedding\n",
        "\n",
        "These get passed in when we make the new object\n",
        "\n",
        "```\n",
        "model = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)\n",
        "\n",
        "```\n",
        "\n",
        "### Saving Variables and ```self```\n",
        "\n",
        "Finally, the last **Object-oriented** concept we'll need allows us to save things within the object. These are sometimes called ``instance variables`` or ``fields``, but the main thing you need to know is **these are like the variables we use all the time to store objects and data**, apart from they belong to the object, and only work within this context\n",
        "\n",
        "We use the keyword ```self``` within the object to refer to itself. We can use this to make layers in the ```__init__()``` function, store them in the object, and then reuse and update them in the ```forward()``` function.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "435z-Ddk6uEH"
      },
      "source": [
        "On every forwards pass (see ``forward()`` below)\n",
        "\n",
        "1. We take a batch of ``users`` and ``movies``\n",
        "\n",
        "\n",
        "2. Run them through the normal embedding and bias embedding layers respectively\n",
        "\n",
        "\n",
        "3. Get the vectors for each out\n",
        "\n",
        "\n",
        "4. Get the dot product of the user and movie vectors\n",
        "\n",
        "\n",
        "5. Add the biases\n",
        "\n",
        "\n",
        "6. Run through a sigmoid\n",
        "\n",
        "\n",
        "7. Return!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtJnQBCF6uEH"
      },
      "outputs": [],
      "source": [
        "class RecommenderNet(torch.nn.Module):\n",
        "    def __init__(self, num_users, num_movies, embedding_size=20):\n",
        "        super().__init__()\n",
        "        self.user_embedding = torch.nn.Embedding(num_users, embedding_size)\n",
        "        self.user_bias = torch.nn.Embedding(num_users, 1)\n",
        "        self.movie_embedding = torch.nn.Embedding(num_movies, embedding_size)\n",
        "        self.movie_bias = torch.nn.Embedding(num_movies, 1)\n",
        "        self.sig = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        #Split out indexes\n",
        "        user_indexes = inputs[:, 0]\n",
        "        movie_indexes = inputs[:, 1]\n",
        "        #Forward pass on embedding layer\n",
        "        user_vector = self.user_embedding(user_indexes)\n",
        "        user_bias = self.user_bias(user_indexes).flatten()\n",
        "        movie_vector = self.movie_embedding(movie_indexes)\n",
        "        movie_bias = self.movie_bias(movie_indexes).flatten()\n",
        "        #Dot product\n",
        "        dot = (user_vector * movie_vector).sum(1)\n",
        "        with_bias = dot + user_bias + movie_bias\n",
        "        #Activation function\n",
        "        output = self.sig(with_bias)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5B0l8aK6uEH"
      },
      "source": [
        "## Lets test it!\n",
        "\n",
        "### Set up model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0cqnsyP6uEH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "d5d790ee-1bcd-48a1-84ec-41866c0db0cb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-a7564291f5c1>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mEMBEDDING_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Make new object (calls __init__())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnum_users\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnum_movies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovie_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecommenderNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_movies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEMBEDDING_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'user_ids' is not defined"
          ]
        }
      ],
      "source": [
        "#Pick Embedding size\n",
        "EMBEDDING_SIZE = 16\n",
        "#Make new object (calls __init__())\n",
        "num_users = len(user_ids)\n",
        "num_movies = len(movie_ids)\n",
        "model = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1Xvcilh6uEI"
      },
      "source": [
        "### Training and Datasets in PyTorch\n",
        "\n",
        "PyTorch requires a little bit of manual set up for the training loop that we got for free in ``Keras`` with the ``fit()`` function.\n",
        "\n",
        "Below we see two for loops, one that loops round every epoch (once through the entire dataset) and inside that that loops through each batch (a subset of a chosen size).\n",
        "\n",
        "``PyTorch`` gives us a ``DataLoader`` object which helps with the batching process.\n",
        "\n",
        "Within that inner loop we pass in part of the training set, calculate the loss and update the weights based on this.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIcx74qu6uEJ"
      },
      "outputs": [],
      "source": [
        "#Pick Embedding size\n",
        "EMBEDDING_SIZE = 16\n",
        "#Make new object (calls __init__())\n",
        "num_users = len(user_ids)\n",
        "num_movies = len(movie_ids)\n",
        "model = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8WDZWj26uEJ"
      },
      "outputs": [],
      "source": [
        "#Use our train - validation split to make DataLoader objects\n",
        "train_dl = DataLoader(MoviesDataset(x_train.values,y_train.values), batch_size=64, shuffle=True)\n",
        "validation_dl = DataLoader(MoviesDataset(x_val.values,y_val.values), batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GM014r0I6uEK"
      },
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "#Use Mean Squared Error as a loss function\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "#Use the Adam algorithm to update the weights based on the loss\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fs54A2VK6uEK",
        "outputId": "96b87b86-6ffb-4faa-fb36-c0c36204fd5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss 0.17324449121952057 Validation Loss 0.11841941624879837\n",
            "Loss 0.07954217493534088 Validation Loss 0.0835493952035904\n",
            "Loss 0.049833301454782486 Validation Loss 0.07055116444826126\n",
            "Loss 0.03789271414279938 Validation Loss 0.06550126522779465\n",
            "Loss 0.03161054849624634 Validation Loss 0.06328113377094269\n",
            "Loss 0.02791447937488556 Validation Loss 0.06368331611156464\n",
            "Loss 0.02549881301820278 Validation Loss 0.0633433535695076\n",
            "Loss 0.0237092487514019 Validation Loss 0.06327226012945175\n",
            "Loss 0.022700462490320206 Validation Loss 0.06252627819776535\n",
            "Loss 0.02190891094505787 Validation Loss 0.06236255541443825\n"
          ]
        }
      ],
      "source": [
        "#Use a for loop to repeat for the desired number of epochs\n",
        "for i in range(epochs):\n",
        "\n",
        "    model.train(True)\n",
        "\n",
        "    #Use a for loop for each batch (provided by the Dataloader)\n",
        "    running_loss = 0.0\n",
        "    for (index, batch) in enumerate(train_dl):\n",
        "\n",
        "        #Get batch\n",
        "        inputs, labels = batch\n",
        "        model.zero_grad()\n",
        "\n",
        "        #Forward pass\n",
        "        prediction = model(inputs)\n",
        "\n",
        "        #Get Loss\n",
        "        loss = loss_fn(prediction, labels)\n",
        "\n",
        "        #Update weights (back prop)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss\n",
        "\n",
        "    avg_loss = running_loss / (index + 1)\n",
        "\n",
        "    model.train(False)\n",
        "\n",
        "    #Now try with the validation set (no need to update weights, just get loss)\n",
        "    running_vloss = 0.0\n",
        "    for index, vdata in enumerate(validation_dl):\n",
        "        vinputs, vlabels = vdata\n",
        "        voutputs = model(vinputs)\n",
        "        vloss = loss_fn(voutputs, vlabels)\n",
        "        running_vloss += vloss\n",
        "\n",
        "    avg_vloss = running_vloss / (index + 1)\n",
        "    print('Loss {} Validation Loss {}'.format(avg_loss, avg_vloss))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SoCTO6X6uEL"
      },
      "source": [
        "### Save and Reload models\n",
        "\n",
        "We can save the weights of our model (the important parts that we have learned) to file so we don't have to train again in future\n",
        "\n",
        "We can then load them into a new model from file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qhYXFyZ6uEL"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTGWSVHp6uEL",
        "outputId": "6de9f313-b746-425f-d779-5bbd218fe818"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RecommenderNet(\n",
              "  (user_embedding): Embedding(671, 16)\n",
              "  (user_bias): Embedding(671, 1)\n",
              "  (movie_embedding): Embedding(9066, 16)\n",
              "  (movie_bias): Embedding(9066, 1)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)\n",
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhueew8w6uEM"
      },
      "source": [
        "### Accessing the Embeddings\n",
        "\n",
        "We can access the **embedding layers** in our model object. This is the embedding and we can see is has a shape of ```num_users x EMBEDDING_SIZE```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AijZN0Wi6uEM",
        "outputId": "2ff23658-dc39-4912-9e88-640e9ac7ea0f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(671, 16, Embedding(671, 16))"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_users, EMBEDDING_SIZE, model.user_embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzQB00YG6uEM"
      },
      "source": [
        "### Making Predictions\n",
        "\n",
        "Now, we can use our trained model to make predictions, and with the predicted ratings, we can pick some recommendations!\n",
        "\n",
        "In order to get the ratings for all movies for a given user, we need to get pass in our data in the form\n",
        "\n",
        "```\n",
        "[\n",
        "    [user_index, movie_1_index],\n",
        "    [user_index, movie_2_index],\n",
        "    [user_index, movie_3_index],\n",
        "    .....\n",
        "]\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26gQNgkN6uEN",
        "outputId": "f8bfecd0-e3b6-4571-a473-6b2dd3d02a33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['movieId', 'title', 'genres'], dtype='object')"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Get the movie data so we can map back to names\n",
        "movie_data = pd.read_csv(\"data/ml-latest-small/movies.csv\")\n",
        "movie_data.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uADRmK976uEN"
      },
      "source": [
        "### Making predictions and `argsort()`\n",
        "\n",
        "Once we have the predicted ratings for each film, we need to get the **Top N**\n",
        "\n",
        "Here we use `np.argsort()`, which does the sort based on the **ratings** but returns the **indexes** rather than the **ratings themselves**. We can then use this to look up the `movie_ids` and then the `title`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4jOQCMs6uEO"
      },
      "outputs": [],
      "source": [
        "def get_top_n(user = 0, n = 10):\n",
        "    #Get Movie Names\n",
        "    top_n_indexes = get_top_n_indexes(user, n)\n",
        "    top_n = get_names_for_indexes(top_n_indexes)\n",
        "    return top_n\n",
        "\n",
        "def get_names_for_indexes(indexes):\n",
        "    return [movie_data[movie_data[\"movieId\"]==movie_ids[i]][\"title\"].item() for i in indexes]\n",
        "\n",
        "def get_top_n_indexes(user = 0, n = 10):\n",
        "    #For one user, make a pair with every movie index\n",
        "    x = torch.IntTensor([[user, i] for i in np.arange(num_movies)])\n",
        "    #Predict\n",
        "    predicted_ratings = model(x)\n",
        "    #Get Top-N indexes\n",
        "    top_n_indexes = predicted_ratings.argsort()[-n:]\n",
        "    return top_n_indexes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElVp0DFI6uEO",
        "outputId": "b9d25f66-4ff7-431f-b996-fe9a2180311d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['American Ninja 3: Blood Hunt (1989)',\n",
              " 'The Lair of the White Worm (1988)',\n",
              " 'Suddenly (1954)',\n",
              " 'Pauline & Paulette (Pauline en Paulette) (2001)',\n",
              " 'Human Centipede II (Full Sequence), The (2011)',\n",
              " 'House II: The Second Story (1987)',\n",
              " 'Next (2007)',\n",
              " 'Postman, The (1997)',\n",
              " 'Cold Creek Manor (2003)',\n",
              " 'Romantics, The (2010)']"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Random users top 10\n",
        "get_top_n(np.random.randint(num_users))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wDIWOty6uEO"
      },
      "source": [
        "# Assessed Assignment 2\n",
        "\n",
        "Please remember to comment your code clearly, submit ``.ipynb``\n",
        "\n",
        "## Task 1\n",
        "\n",
        "We're going to ask you take the trained model and write the code to make two metrics - **Diversity** and **Novelty**. You should end up with **one statistic** for each that tells you something about the recommendations of the trained model based on the **whole dataset**.\n",
        "\n",
        "\n",
        "#### Pro Tip\n",
        "\n",
        "This will take quite a long time to run on the whole dataset, so start off by trying to get the code to work for **one user**, then expand to **two users**, then **every user**.\n",
        "\n",
        "### Diversity\n",
        "\n",
        "This tells us what the mean diversity (inverse of the similarity, based on movie embeddings) between each film in every users Top 10 films is.\n",
        "\n",
        "1. Calculate every user's top 10\n",
        "\n",
        "\n",
        "2. For each top 10, get the embedding for each film then use this to calculate the similarity matrix\n",
        "\n",
        "\n",
        "3. Invert similarity to get the difference\n",
        "\n",
        "\n",
        "4. Get mean difference for each top 10\n",
        "\n",
        "\n",
        "5. Report the mean for whole dataset (every top 10)\n",
        "\n",
        "\n",
        "### Novelty\n",
        "\n",
        "This tells us what the mean popularity (e.g. mean rating) of the films in every users Top 10 films is\n",
        "\n",
        "1. Calculate every user's top 10\n",
        "\n",
        "\n",
        "2. For each top 10, get the mean rating for each film (based on the original **MovieLens Small** dataset (``df = pd.read_csv(\"ml-latest-small/ratings.csv\")``).\n",
        "\n",
        "\n",
        "3. Get the mean rating for each top 10.\n",
        "\n",
        "\n",
        "4. Report the mean for the whole dataset (every top 10).\n",
        "\n",
        "\n",
        "\n",
        "## Task 2\n",
        "\n",
        "Using a dimensionality reduction approach (PCA? TSNE?), plot the top 30 best rated films on a 2-D graph based on their movie embeddings. Label each point with the title.\n",
        "\n",
        "There is infact ~400 films that have an average rating of 5 (because some films have only 1 rating). Can you adjust or filter for this?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSJVuh1U6uEP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}